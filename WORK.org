
* <2025-12-05 ven. 07:09>  Interface
  firefox is able to load the room visualisation but not brave
  investigate and explain and propose a solution
  Here is the log for firefox
  '''
  '''(gen) mlk@leur ~/TU/Academics/Schedules/schedule_checker_app $ ./run.sh -d
Running in development mode...
 * Serving Flask app 'online_schedule_checker.py'
 * Debug mode: off
2025-12-04 19:45:35,734 MainThread~20 /_internal.py@97@_log/ WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
2025-12-04 19:45:35,734 MainThread~20 /_internal.py@97@_log/ Press CTRL+C to quit
2025-12-04 19:45:46,350 Thread-1 (process_request_thread)~20 /class_schedule.py@36@general_cleaning/ Starting general cleaning of the data.
2025-12-04 19:45:46,370 Thread-1 (process_request_thread)~20 /class_schedule.py@58@general_cleaning/ Completed general cleaning.
2025-12-04 19:45:46,370 Thread-1 (process_request_thread)~20 /helper.py@54@process_schedule/ Completed general cleaning
2025-12-04 19:45:46,370 Thread-1 (process_request_thread)~20 /class_schedule.py@73@clean_and_harmonize_times/ cleaning and harmonizing times.
/home/mlk/TU/Academics/Schedules/schedule_checker_app/class_schedule/class_schedule.py:91: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.
  rows_with_pm_repeated = time_series.str.contains(r"(?P<A>pm).*(?P=A)")
2025-12-04 19:45:46,379 Thread-1 (process_request_thread)~20 /class_schedule.py@92@clean_and_harmonize_times/ pm is repeating in rows no
''' and those of brave
'''JavaScript Error: Maximum call stack size exceeded

This usually means there's a typo in your chart specification. See the javascript console for the full traceback.''' vega@5:1 WARN Channel size should not be used with an unsorted discrete field.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-03T01:01:00\")}"},{"signal":"{data: datetime(\"2025-02-03T18:30:00\")}"}] and [["2025-02-03T01:01:00","2025-02-03T18:30:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-04T01:01:00\")}"},{"signal":"{data: datetime(\"2025-02-04T18:00:00\")}"}] and [["2025-02-04T01:01:00","2025-02-04T18:00:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-05T08:00:00\")}"},{"signal":"{data: datetime(\"2025-02-05T19:30:00\")}"}] and [["2025-02-05T08:00:00","2025-02-05T19:30:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-06T08:00:00\")}"},{"signal":"{data: datetime(\"2025-02-06T19:30:00\")}"}] and [["2025-02-06T08:00:00","2025-02-06T19:30:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-07T08:00:00\")}"},{"signal":"{data: datetime(\"2025-02-07T19:30:00\")}"}] and [["2025-02-07T08:00:00","2025-02-07T19:30:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 WARN Conflicting scale property "domain" ([{"signal":"{data: datetime(\"2025-02-08T08:00:00\")}"},{"signal":"{data: datetime(\"2025-02-08T19:30:00\")}"}] and [["2025-02-08T08:00:00","2025-02-08T19:30:00"]]). Using the union of the two domains.
m @ vega@5:1
vega@5:1 Uncaught (in promise) RangeError: Maximum call stack size exceeded'''

* <2025-12-04 jeu. 19:43>  General Schedule
you can look for the row with No. and then take the data from them but remove the row where all is na (the next one for example).
make sure the header are correctly translated.  This should help solve this error
3      False
4      False
5      False
6      False
7      False
       ...  
'''
363    False
364    False
365    False
366    False
367    False
Name: time, Length: 361, dtype: bool
2025-12-04 19:45:46,381 Thread-1 (process_request_thread)~20 /class_schedule.py@96@clean_and_harmonize_times/ rows with . in the time no
3      False
4      False
5      False
6      False
7      False
       ...  
363    False
364    False
365    False
366    False
367    False
Name: time, Length: 361, dtype: bool
2025-12-04 19:45:46,383 Thread-1 (process_request_thread)~20 /class_schedule.py@100@clean_and_harmonize_times/ rows with ; in the time no
3      False
4      False
5      False
6      False
7      False
       ...  
363    False
364    False
365    False
366    False
367    False
Name: time, Length: 361, dtype: bool
2025-12-04 19:45:46,395 Thread-1 (process_request_thread)~20 /class_schedule.py@116@clean_and_harmonize_times/ Completed time cleaning and harmonization.
2025-12-04 19:45:46,395 Thread-1 (process_request_thread)~20 /helper.py@57@process_schedule/ Completed cleaning and harmonizing times
2025-12-04 19:45:46,395 Thread-1 (process_request_thread)~20 /helper.py@59@process_schedule/ Starting with applied epidemiology a special course to split in 2
2025-12-04 19:45:46,398 Thread-1 (process_request_thread)~20 /helper.py@61@process_schedule/ Completed special applied epidemiology course
2025-12-04 19:45:46,398 Thread-1 (process_request_thread)~20 /class_schedule.py@130@getting_start_end_times/ Extracting start and end times from the time column.
2025-12-04 19:45:46,553 Thread-1 (process_request_thread)~20 /class_schedule.py@140@getting_start_end_times/ Completed extraction of start and end times.
2025-12-04 19:45:46,554 Thread-1 (process_request_thread)~20 /helper.py@64@process_schedule/ Completed getting start and end times
2025-12-04 19:45:46,554 Thread-1 (process_request_thread)~20 /class_schedule.py@151@add_duration/ Calculating course durations.
2025-12-04 19:45:46,658 Thread-1 (process_request_thread)~20 /class_schedule.py@161@add_duration/ Completed calculation of course durations.
2025-12-04 19:45:46,658 Thread-1 (process_request_thread)~20 /helper.py@67@process_schedule/ Completed adding duration
2025-12-04 19:45:46,658 Thread-1 (process_request_thread)~40 /online_schedule_checker.py@74@upload_file/ An error occured: 'DataFrame' object has no attribute 'course_code'
Traceback (most recent call last):
  File "/mnt/backup/Prog/Git/schedule_checker_app/online_schedule_checker.py", line 58, in upload_file
    processed_df = process_schedule(fname, normalized_sheet or "GENERAL SCHEDULE")
  File "/home/mlk/TU/Academics/Schedules/schedule_checker_app/class_schedule/helper.py", line 69, in process_schedule
    df = harmonize_course_codes(df)
  File "/home/mlk/TU/Academics/Schedules/schedule_checker_app/class_schedule/class_schedule.py", line 339, in harmonize_course_codes
    df.loc[:, "course_code"] = df.course_code.apply(
                               ^^^^^^^^^^^^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/pandas/core/generic.py", line 6299, in __getattr__
    return object.__getattribute__(self, name)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
AttributeError: 'DataFrame' object has no attribute 'course_code'. Did you mean: 'course_no'?
2025-12-04 19:45:46,666 Thread-1 (process_request_thread)~40 /app.py@875@log_exception/ Exception on /upload [POST]
Traceback (most recent call last):
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
           ~~~~~~~~~~~~~~~~~~~~~^^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 1212, in make_response
    raise TypeError(
    ...<3 lines>...
    )
TypeError: The view function for 'upload_file' did not return a valid response. The function either returned None or ended without a return statement.
2025-12-04 19:45:46,669 Thread-1 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:45:46] "POST /upload HTTP/1.1" 500 -


''' happening this time when loading the 'GENERAL SCHEDULE' of 'Data/FINAL SCHEDULE SEMESTEWR II 2024-2025_v2.xlsx'


* <2025-12-04 jeu. 19:29>
  I've updated the table by removing the unecessary row so now the row 0 is the header row.
  secondly I renamed the schedule file to Data/semI_final_exam_schedule_ay_25-26.xlsx.

  Take this in account to adapte the code to first try load the table using row 0 as header and if it doesn't work load the row 9 (or 8 what ever was done before).

* <2025-12-04 jeu. 19:15> Loading Sheet FINAL EXAM SCHEDULE of semI_final_exam_schedule_ay_25-26.xlsx 
  (gen) mlk@leur ~/TU/Academics/Schedules/schedule_checker_app $ ./run.sh -d
Running in development mode...
 * Serving Flask app 'online_schedule_checker.py'
 * Debug mode: off
2025-12-04 19:12:28,258 MainThread~20 /_internal.py@97@_log/ WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
2025-12-04 19:12:28,258 MainThread~20 /_internal.py@97@_log/ Press CTRL+C to quit
2025-12-04 19:12:42,460 Thread-1 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:12:42] "GET / HTTP/1.1" 200 -
2025-12-04 19:12:42,592 Thread-3 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:12:42] "GET /static/js/index.js HTTP/1.1" 304 -
2025-12-04 19:12:42,593 Thread-2 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:12:42] "GET /static/css/index.css HTTP/1.1" 304 -
2025-12-04 19:12:43,329 Thread-4 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:12:43] "GET /favicon.ico HTTP/1.1" 404 -
2025-12-04 19:14:47,219 Thread-5 (process_request_thread)~20 /class_schedule.py@36@general_cleaning/ Starting general cleaning of the data.
2025-12-04 19:14:47,225 Thread-5 (process_request_thread)~40 /online_schedule_checker.py@69@upload_file/ An error occured: single positional indexer is out-of-bounds
Traceback (most recent call last):
  File "/mnt/backup/Prog/Git/schedule_checker_app/online_schedule_checker.py", line 53, in upload_file
    processed_df = process_schedule(fname, sheet_name)
  File "/home/mlk/TU/Academics/Schedules/schedule_checker_app/class_schedule/helper.py", line 53, in process_schedule
    df = general_cleaning(df)
  File "/home/mlk/TU/Academics/Schedules/schedule_checker_app/class_schedule/class_schedule.py", line 52, in general_cleaning
    if isinstance(df[c].iloc[0], str):
                  ~~~~~~~~~~^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/pandas/core/indexing.py", line 1191, in __getitem__
    return self._getitem_axis(maybe_callable, axis=axis)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/pandas/core/indexing.py", line 1752, in _getitem_axis
    self._validate_integer(key, axis)
    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/pandas/core/indexing.py", line 1685, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds
2025-12-04 19:14:47,233 Thread-5 (process_request_thread)~40 /app.py@875@log_exception/ Exception on /upload [POST]
Traceback (most recent call last):
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 920, in full_dispatch_request
    return self.finalize_request(rv)
           ~~~~~~~~~~~~~~~~~~~~~^^^^
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 939, in finalize_request
    response = self.make_response(rv)
  File "/home/mlk/.pyenv/versions/3.13.9/envs/gen/lib/python3.13/site-packages/flask/app.py", line 1212, in make_response
    raise TypeError(
    ...<3 lines>...
    )
TypeError: The view function for 'upload_file' did not return a valid response. The function either returned None or ended without a return statement.
2025-12-04 19:14:47,237 Thread-5 (process_request_thread)~20 /_internal.py@97@_log/ 127.0.0.1 - - [04/Dec/2025 19:14:47] "POST /upload HTTP/1.1" 500 -

* Note : we are only interested in the in "FINAL EXAM SCHEDULE" and "GENERAL SCHEDULE" sheets

** Raw extraction
# > make sure we have the required excel parser
# > make this snippet below a small helper
#+BEGIN_SRC python
  #> have some data wrangin whith something like
  df = df.apply(lambda s:s.str.strip().str.replace(r'\s+', ' ', regex=True))
  #> and renove that strip code from the rest of the code latter
  
  def get_no_index(raw):
       def _f(row):
           return row.astype(str).str.contains("N0.",case=False, na=False)   
      return raw.apply(get_no_index).any(axis=1)
  
  _f(row).any(axis=1)
  
   def load_exam_sheet(xl: pd.ExcelFile, sheet: str) -> pd.DataFrame:
       raw = xl.parse(sheet, header=None)
       header_idx = raw.index[get_no_index(raw)][0]
       header = (
           raw.iloc[header_idx]
           #> is fillna ffill necessary explain
                .fillna(method="ffill")
                # > do the str.strip() on all data before reaching here.
                # > and the replace
                .str.strip()
                .str.replace(r"\s+", " ", regex=True)
            )
            df = (
                raw.iloc[header_idx + 2 :]
                .dropna(how="all")
                .reset_index(drop=True)
            )
            df.columns = header
            return df
  
#+END_SRC
      - Works for both the general exam sheet and the ACCESS-only tabs, because
        each uses the “N0.” row to introduce the table.
** Column harmonization

#+BEGIN_SRC python
  COLUMN_MAP = {
      "N0.": "no",
      "Course Code ": "course_code",
      "Course N0.": "course_no",
      "Course Title": "course_title",
      "Sec": "section",
      "Day & Time": "day_time",
      "Location/Room": "location",
      "Instructor/ Proctor": "instructor",
      "Exam Day ": "exam_date",
      "Exam Date": "exam_date",  # ACCESS sheet
      "Remedial Program Schedule": "program",  # ignored later
      "Time ": "time",
  }
  
  
  def normalize_columns(df, sheet):
      # once again the strip of the columns header should be done at an earlier wrangling cleaning phase,
      df = df.rename(columns={c: COLUMN_MAP.get(c, c.lower().strip()) for c in df.columns})
      df["college"] = sheet  # or parse from the title row if you want the official name
      # not needed for the 2 sheets under investigation
      df = df.drop(
          columns=[c for c in df.columns if c.startswith("Unnamed")], errors="ignore"
      )
      df = df.dropna(subset=["course_code", "course_no"], how="all")
      return df
#+END_SRC
** Derive exam timestamps (reuses existing utilities)

#+BEGIN_SRC python
  from class_schedule.utilities import clean, split_time_interval, get_datetimes
  
  
  # > do not write     df[["sts", "ets"]] = datetimes
  # > but     df.loc[:,["sts", "ets"]] = datetimes
  # > apply this consitently
  
  
  def parse_exam_times(df):
      def _split_day_time(value):
          if not isinstance(value, str):
              return None, None
          parts = value.split(" ", 1)
          day = parts[0]
          time_str = parts[1].replace(" ", "")
          return day, time_str
  
      df[["weekday_text", "time"]] = df["day_time"].apply(
          lambda v: pd.Series(_split_day_time(v))
      )
      # > integrate this into clean_and_harmonize times
      df["time"] = df["time"].str.replace("–", "-")
      df["time"] = df["time"].str.replace("pmPM", "pm", regex=False)
      df = clean_and_harmonize_times(df)  # from class_schedule.class_schedule
      times = df["time"].apply(split_time_interval).apply(pd.Series)
      times.columns = ["stime", "etime", "meridium"]
  
      # > use loc. It is the best practice
      df.loc[:, ["stime", "etime", "meridium"]] = times
      datetimes = df[["stime", "etime", "meridium"]].apply(
          get_datetimes, axis=1, result_type="expand"
      )
      datetimes.columns = ["sts", "ets"]
  
      df[["sts", "ets"]] = datetimes
  
      # Overwrite the date portion with the actual exam date column
      df["exam_date"] = pd.to_datetime(df["exam_date"]).dt.date
      df["sts"] = df.apply(
          lambda row: pd.Timestamp.combine(row["exam_date"], row["sts"].time()), axis=1
      )
      df["ets"] = df.apply(
          lambda row: pd.Timestamp.combine(row["exam_date"], row["ets"].time()), axis=1
      )
      return df
#+END_SRC   
      - This lets us keep the same Vega-ready sts/ets columns your visualization pipeline expects.
      - The weekday_text column becomes the label used in Vega, while sts.dt.day_name() still produces the canonical weekday.

** Assemble a Vega-friendly frame
#+BEGIN_SRC python
  def build_exam_records(df):
      df["start_time"] = df["sts"].dt.strftime("%H:%M")
      df["end_time"] = df["ets"].dt.strftime("%H:%M")
      df["weekday"] = df["sts"].dt.day_name()
      df["cid"] = df.apply(
          lambda row: f"{row.course_code}_{row.course_no}_exam_{row.section}".lower(),
          axis=1,
      )
      return df.loc[
          :,
          [
              "sts",
              "ets",
              "weekday",
              "course_code",
              "course_no",
              "course_title",
              "section",
              "instructor",
              "location",
              "college",
              "start_time",
              "end_time",
              "exam_date",
              "cid",
          ],
      ]
#+END_SRC

** Entry point

#+BEGIN_SRC python
  def process_exam_workbook(path: str, sheets=None):
      xl = pd.ExcelFile(path)
      selected = sheets or ["FINAL EXAM SCHEDULE"]  # extend as needed
      frames = [
          build_exam_records(
              parse_exam_times(normalize_columns(load_exam_sheet(xl, sheet), sheet))
          )
          for sheet in selected
      ]
      return pd.concat(frames, ignore_index=True)
#+END_SRC


